{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442c9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.49047908 0.         0.         0.37302199\n",
      "  0.49047908 0.37302199 0.         0.         0.49047908]\n",
      " [0.5        0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.5        0.5        0.        ]\n",
      " [0.         0.5628291  0.         0.5628291  0.         0.42804604\n",
      "  0.         0.42804604 0.         0.         0.        ]]\n",
      "\n",
      "LDA Topics:\n",
      "Topic 1: love, data, science, machine, learning\n",
      "Topic 2: challenging, language, natural, amazing, processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c491aa2e40c74fa19e31aafa2119f2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\w065pxg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\w065pxg\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acc2ea885264f6a848c13faca798e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85a1591acbe4924945f0cd67af283f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2040506e441a4a60afa7731a603c72eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886813a83dbb49b8aaa5ce5e7a1a891e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccd1dfffdca4c88b465b317e0532442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea68d7153f4f45beafbf076c373a5847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56634bdcd0794d84a522e30d0eab2d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca679d93952471d923da14388419270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc326655abc49afa97991c2008445f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5053666cda4e6090ec62c179a4d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT similarity between 'data' and 'learning': 0.4596\n",
      "\n",
      "Sentiment Analysis (TextBlob):\n",
      "'I love data science and machine learning.' → Sentiment polarity: 0.50\n",
      "'Natural language processing is amazing.' → Sentiment polarity: 0.35\n",
      "'Machine learning is challenging but fun.' → Sentiment polarity: 0.40\n",
      "\n",
      "Sentiment Analysis (VADER):\n",
      "'I love data science and machine learning.' → Sentiment Scores: {'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.6369}\n",
      "'Natural language processing is amazing.' → Sentiment Scores: {'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.743}\n",
      "'Machine learning is challenging but fun.' → Sentiment Scores: {'neg': 0.0, 'neu': 0.41, 'pos': 0.59, 'compound': 0.6956}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Sample JSON Data\n",
    "data = [\n",
    "    {\"id\": 1, \"text\": \"I love data science and machine learning.\"},\n",
    "    {\"id\": 2, \"text\": \"Natural language processing is amazing.\"},\n",
    "    {\"id\": 3, \"text\": \"Machine learning is challenging but fun.\"}\n",
    "]\n",
    "\n",
    "# Extract documents\n",
    "documents = [item[\"text\"] for item in data]\n",
    "\n",
    "# --- 2. TF-IDF Vectorization ---\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "# --- 3. LDA Topic Modeling ---\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda.fit(count_matrix)\n",
    "\n",
    "print(\"\\nLDA Topics:\")\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    words = [count_vectorizer.get_feature_names_out()[j] for j in topic.argsort()[-5:]]\n",
    "    print(f\"Topic {i+1}: {', '.join(words)}\")\n",
    "\n",
    "# --- 4. Word Embeddings (BERT via Sentence Transformers) ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast and efficient\n",
    "\n",
    "data_embedding = model.encode(\"data\", convert_to_tensor=True)\n",
    "learning_embedding = model.encode(\"learning\", convert_to_tensor=True)\n",
    "\n",
    "similarity = util.pytorch_cos_sim(data_embedding, learning_embedding).item()\n",
    "print(f\"\\nBERT similarity between 'data' and 'learning': {similarity:.4f}\")\n",
    "\n",
    "# --- 5. Sentiment Analysis (TextBlob) ---\n",
    "print(\"\\nSentiment Analysis (TextBlob):\")\n",
    "for doc in documents:\n",
    "    blob = TextBlob(doc)\n",
    "    print(f\"'{doc}' → Sentiment polarity: {blob.sentiment.polarity:.2f}\")\n",
    "\n",
    "# --- 6. Sentiment Analysis (VADER) ---\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "print(\"\\nSentiment Analysis (VADER):\")\n",
    "for doc in documents:\n",
    "    score = analyzer.polarity_scores(doc)\n",
    "    print(f\"'{doc}' → Sentiment Scores: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
